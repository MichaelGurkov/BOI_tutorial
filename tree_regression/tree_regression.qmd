---
title: "Tree Regression with Boston Housing Data"
format: html
---

Welcome to this comprehensive tutorial on tree regression. This tutorial aims to introduce the concept of tree regression, provide a detailed explanation of the code involved, and demonstrate its implementation using the Boston Housing dataset. Tree regression is a powerful tool for predicting continuous outcomes based on input features, and it is widely used in various fields.

## What is Tree Regression?

Tree regression is a type of decision tree that is used for predicting continuous values. Unlike classification trees that predict discrete class labels, regression trees predict a continuous target variable. The tree is constructed by recursively splitting the data into subsets based on the values of input features, aiming to minimize the variance within each subset.

## Loading Necessary Libraries

First, we need to load the required libraries for our analysis. We will use `tidyverse` for data manipulation and visualization and `tidymodels` for model fitting.

```{r}
library(tidyverse)
library(tidymodels)
library(rpart.plot)
```

## Load the Data

Next, we'll select the relevant columns from the Boston housing dataset.

```{r load_data}
boston_data = MASS::Boston %>%
  select(medv, lstat)
```

## Visualizing the Data

We start by visualizing the relationship between the predictor variable `lstat` and the target variable `medv` from the `boston_data` dataset.

```{r}
boston_data %>% 
  ggplot(aes(lstat, medv)) + 
  geom_point()
```

## Fitting the Tree Regression Model

Next, we fit a tree regression model to predict `medv` using `lstat` as the predictor. We specify the model parameters, including the tree depth, minimum number of observations in a node, and the engine to be used.

```{r}
tree_model_fit = decision_tree(
  cost_complexity = 0,
  tree_depth = 2,
  mode = "regression",
  engine = "rpart",
  min_n = 5
) %>%
  fit(medv ~ lstat, data = boston_data)
```

## Making Predictions

Once the model is fitted, we use it to make predictions on the `boston_data`.

```{r}
predictions = tree_model_fit %>% 
  predict(boston_data)
```

## Visualizing the Tree

Finally, we visualize the structure of the fitted tree to understand how the splits are made and how the predictions are generated.

```{r}
tree_model_fit %>% 
  extract_fit_engine() %>% 
  rpart.plot(roundint = FALSE)
```

## Conclusion

This tutorial has provided an in-depth look at tree regression, from concept to implementation in R. By visualizing the data, fitting the model, making predictions, and visualizing the tree structure, we have demonstrated the entire process of tree regression analysis. Understanding these methods and their applications will enhance your ability to analyze and interpret continuous data effectively.